# Herbal Spectral Classification Using CNN with SMOTE Oversampling

This repository contains Python scripts used for building, training, and evaluating a 1D Convolutional Neural Network (CNN) for herbal spectral classification tasks. The pipeline integrates preprocessing, synthetic oversampling using SMOTE, training, testing, and evaluation.

---

## File Descriptions

The repository includes the following key scripts and data files:

* `CNN_SMOTE_train_new.py`: Applies SMOTE to training data and prepares it for model training.
* `CNN_SMOTE_test_new.py`: Applies SMOTE to test data.
* `mycnn_model_v2.py`: Defines and trains a CNN model with cross-validation.
* `preprocess_data_new_train.py`: Preprocesses training data.
* `preprocess_data_new_test.py`: Preprocesses test data.
* `random_split.py`: Randomly splits the dataset into training and testing sets.
* `stresstest_new.py`: Evaluates trained models on test data using confusion matrix and classification report.
* `run_wrapper.py`: (Optional utility wrapper if applicable).
* `raw_sample.csv`: Sample data format reference.

---

## Input Data Format

A CSV file named `raw.csv` must be provided, containing the raw herbal spectral data. The format is as follows:

1. **Column 0 (`Sample`)**: A unique identifier string for each sample (e.g., `jinhuacha batch 2 sample 11 repeat`).
2. **Column 1 (`Type`)**: The class or category label for each sample (e.g., `Flower`, `Seed`, etc.).
3. **Column 2 onward**: FTIR or other experimental measurements at various wavelengths (e.g., column headers like `1900`, `1899`, ..., `800`).

> âš ï¸ **Requirement**: Each class (type) in `raw.csv` must contain **at least 6 samples**. The pipeline will not execute properly if this condition is not met.

---

## Procedure

### 0. Ensure Class Sample Sufficiency

Before starting, verify that each class in `raw.csv` has at least **6 samples**. If any class has fewer (e.g., 4â€“5 samples), you must **manually add mock samples**.

Mock data can be generated by using tools like **ChatGPT**, e.g., averaging existing samples or adding Gaussian noise. Do **not** add excessive mock samples as it may reduce the integrity of your dataset.

### 1. Edit `random_split.py`

Set the input data path by editing:

```python
filein = 'raw.csv'
```

Or use another file (e.g., `jinhuacha_with_mock_seed.csv`).

### 2. Generate Train/Test CSV Files

```bash
python random_split.py
```

Outputs:

* `train_new.csv`
* `test_new.csv`

### 3. Preprocess Training Data

```bash
python preprocess_data_new_train.py
```

Outputs:

* `config_train_new.npy`
* `label_train_new.npy`
* Diagnostic `.png` visualizations (inspect for correctness)

### 4. Customize SMOTE Sampling Strategy

In `CNN_SMOTE_train_new.py`, set the oversampling rate:

```python
sample_strategy = dict.fromkeys(sample_strategy, 500)
```

### 5. Apply SMOTE to Training Data

```bash
python CNN_SMOTE_train_new.py
```

Outputs:

* `X_train_new.npy`
* `Y_train_new.npy`

### 6. Edit Model Hyperparameters

In `mycnn_model_v2.py`, optionally configure cross-validation:

```python
kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)
```

Default: `n_splits = 4`

### 7. Train CNN Model

```bash
python mycnn_model_v2.py
```

Outputs:

* `model_fold0.h5`, ..., `model_fold3.h5` (CNN models)
* `learning_curve_*.png` (training/validation plots)

### 8. Preprocess Test Data

```bash
python preprocess_data_new_test.py
```

Outputs:

* `config_test_new.npy`
* `label_test_new.npy`
* Diagnostic `.png` visualizations

### 9. Customize SMOTE for Test Data

In `CNN_SMOTE_test_new.py`, again set:

```python
sample_strategy = dict.fromkeys(sample_strategy, 500)
```

### 10. Apply SMOTE to Test Data

```bash
python CNN_SMOTE_test_new.py
```

Outputs:

* `X_test_new.npy`
* `Y_test_new.npy`

### 11. Evaluate Model Accuracy

Edit `stresstest_new.py` to select a model:

```python
fold_no = 2
mpath = f"model_fold{fold_no}.h5"
```

Run:

```bash
python stresstest_new.py
```

Outputs:

* `cm_plot_{fold_no}.png` (confusion matrix)
* `REPORT_{fold_no}.txt` (detailed classification report)

### 12. Evaluate All Folds (Recommended)

Repeat Step 11 for all model folds (`fold_no = 0, 1, 2, 3`).

> ğŸ” **Goal**: Assess consistency of accuracy across folds and classes. Consistent results imply a robust model. Poorly performing classes may indicate data imbalance or insufficient original samples.

---

## Notes

* This pipeline assumes a minimum level of Python and data handling proficiency.
* Oversampling with SMOTE is used only when sample size per class is sufficient. Avoid overuse of synthetic data.

